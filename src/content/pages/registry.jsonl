{"date": "2023-06-28T18:10:55.509719", "model_metadata": {"gpt-3.5-turbo-0301:20230614": {"model_id": "gpt-3.5-turbo-0301:20230614", "path": "answers/rakuda_v1/gpt3.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-ppo": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "path": "answers/rakuda_v1/rinna-ppo.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "path": "answers/rakuda_v1/rinna-sft.jsonl"}, "rinna/japanese-gpt-neox-3.6b": {"model_id": "rinna/japanese-gpt-neox-3.6b", "path": "answers/rakuda_v1/rinna.jsonl"}, "izumi-lab/stormy-7b-10ep": {"model_id": "izumi-lab/stormy-7b-10ep", "path": "answers/rakuda_v1/stormy.jsonl"}, "cyberagent/open-calm-7b": {"model_id": "cyberagent/open-calm-7b", "path": "answers/rakuda_v1/calm.jsonl"}}, "metadata": {"questions_path": "questions/rakuda_v1.jsonl", "reviewer_path": "prompts/rakuda_reviewer.jsonl", "prompt_path": "prompts/rakuda_prompt.jsonl"}, "ranking": [{"model_id": "rinna/japanese-gpt-neox-3.6b", "short_name": "rinna-3.6b", "median": -0.7503310531398228, "one_sigma_down": 0.10017338424683819, "one_sigma_up": 0.0991624823148497, "win_rate": 0.35125, "stronger_than_next_confidence": 0, "implied_win_probability": 0}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "short_name": "rinna-3.6b-SFT", "median": -0.7188850623809692, "one_sigma_down": 0.10084014078765635, "one_sigma_up": 0.09975039004731556, "win_rate": 0.35875, "stronger_than_next_confidence": 0.5853008474576271, "implied_win_probability": 0.5078608499333815}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "short_name": "rinna-3.6b-PPO", "median": -0.5753167201785611, "one_sigma_down": 0.09831405058106879, "one_sigma_up": 0.09829877789967173, "win_rate": 0.3925, "stronger_than_next_confidence": 0.8377531779661017, "implied_win_probability": 0.5358305621120212}, {"model_id": "izumi-lab/stormy-7b-10ep", "short_name": "stormy-7b", "median": -0.3835133333724112, "one_sigma_down": 0.09694851881151118, "one_sigma_up": 0.09754290728280562, "win_rate": 0.43875, "stronger_than_next_confidence": 0.9087330508474576, "implied_win_probability": 0.5478043820331442}, {"model_id": "cyberagent/open-calm-7b", "short_name": "open-calm-7b", "median": -0.06256778701634562, "one_sigma_down": 0.09747332104552651, "one_sigma_up": 0.09736005425987745, "win_rate": 0.515, "stronger_than_next_confidence": 0.9867192796610169, "implied_win_probability": 0.5795546717417311}, {"model_id": "gpt-3.5-turbo-0301:20230614", "short_name": "gpt-3.5", "median": 2.4877740910918504, "one_sigma_down": 0.17804337562614858, "one_sigma_up": 0.188354483423951, "win_rate": 0.94375, "stronger_than_next_confidence": 1.0, "implied_win_probability": 0.9275964789568163}]}
{"date": "2023-07-14T15:20:53.234820", "model_metadata": {"gpt-4:20230713": {"model_id": "gpt-4:20230713", "path": "answers/rakuda_v1/gpt4.jsonl"}, "gpt-3.5-turbo-0301:20230614": {"model_id": "gpt-3.5-turbo-0301:20230614", "path": "answers/rakuda_v1/gpt3.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-ppo": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "path": "answers/rakuda_v1/rinna-ppo.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "path": "answers/rakuda_v1/rinna-sft.jsonl"}, "rinna/japanese-gpt-neox-3.6b": {"model_id": "rinna/japanese-gpt-neox-3.6b", "path": "answers/rakuda_v1/rinna.jsonl"}, "izumi-lab/stormy-7b-10ep": {"model_id": "izumi-lab/stormy-7b-10ep", "path": "answers/rakuda_v1/stormy.jsonl"}, "cyberagent/open-calm-7b": {"model_id": "cyberagent/open-calm-7b", "path": "answers/rakuda_v1/calm.jsonl"}, "rwkv-world-jpn-55": {"model_id": "rwkv-world-jpn-55", "path": "answers/rakuda_v1/rwkv.jsonl"}, "super-torin-sama-alpha2": {"model_id": "super-torin-sama-alpha2", "path": "answers/rakuda_v1/super-torin.jsonl"}}, "metadata": {"questions_path": "questions/rakuda_v1.jsonl", "reviewer_path": "prompts/gpt4_reviewer.jsonl", "prompt_path": "prompts/rakuda_prompt.jsonl"}, "ranking": [{"model_id": "rinna/japanese-gpt-neox-3.6b", "median": 698.7910267541656, "one_sigma_up": 36.39529035193573, "one_sigma_down": 37.09254466604614, "stronger_than_next_confidence": -1.0, "win_rate": 0.1657754010695187, "short_name": "rinna-3.6b"}, {"model_id": "cyberagent/open-calm-7b", "median": 791.3143222750169, "one_sigma_up": 32.78265513124438, "one_sigma_down": 33.679762198974345, "stronger_than_next_confidence": 0.9715525, "win_rate": 0.27325581395348836, "short_name": "open-calm-7b"}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "median": 810.8620649003119, "one_sigma_up": 33.40152463323159, "one_sigma_down": 34.14239430217083, "stronger_than_next_confidence": 0.6575575, "win_rate": 0.29874213836477986, "short_name": "rinna-3.6b-SFT"}, {"model_id": "izumi-lab/stormy-7b-10ep", "median": 845.2533406403094, "one_sigma_up": 32.50929823949912, "one_sigma_down": 33.47132870793223, "stronger_than_next_confidence": 0.7662375, "win_rate": 0.3282208588957055, "short_name": "stormy-7b"}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "median": 858.878798034552, "one_sigma_up": 33.66522340270626, "one_sigma_down": 32.78757766127194, "stronger_than_next_confidence": 0.61937, "win_rate": 0.38741721854304634, "short_name": "rinna-3.6b-PPO"}, {"model_id": "super-torin-sama-alpha2", "median": 1011.0492399694623, "one_sigma_up": 31.882177939431926, "one_sigma_down": 31.22267038079849, "stronger_than_next_confidence": 0.99954, "win_rate": 0.5706214689265536, "short_name": "supertrin"}, {"model_id": "rwkv-world-jpn-55", "median": 1076.450569713049, "one_sigma_up": 34.04521187391629, "one_sigma_down": 32.972197059167456, "stronger_than_next_confidence": 0.9119575, "win_rate": 0.5338983050847458, "short_name": "rwkv-world"}, {"model_id": "gpt-3.5-turbo-0301:20230614", "median": 1384.6403103005816, "one_sigma_up": 44.63811984801714, "one_sigma_down": 43.16825198495212, "stronger_than_next_confidence": 1.0, "win_rate": 0.8442211055276382, "short_name": "gpt-3.5"}, {"model_id": "gpt-4:20230713", "median": 1520.9151737171537, "one_sigma_up": 54.08307464054769, "one_sigma_down": 49.87973981999494, "stronger_than_next_confidence": 0.992815, "win_rate": 0.9255813953488372, "short_name": "gpt-4"}]}
