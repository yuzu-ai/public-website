{"date": "2023-06-28T18:10:55.509719", "model_metadata": {"gpt-3.5-turbo-0301:20230614": {"model_id": "gpt-3.5-turbo-0301:20230614", "path": "answers/rakuda_v1/gpt3.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-ppo": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "path": "answers/rakuda_v1/rinna-ppo.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "path": "answers/rakuda_v1/rinna-sft.jsonl"}, "rinna/japanese-gpt-neox-3.6b": {"model_id": "rinna/japanese-gpt-neox-3.6b", "path": "answers/rakuda_v1/rinna.jsonl"}, "izumi-lab/stormy-7b-10ep": {"model_id": "izumi-lab/stormy-7b-10ep", "path": "answers/rakuda_v1/stormy.jsonl"}, "cyberagent/open-calm-7b": {"model_id": "cyberagent/open-calm-7b", "path": "answers/rakuda_v1/calm.jsonl"}}, "metadata": {"questions_path": "questions/rakuda_v1.jsonl", "reviewer_path": "prompts/rakuda_reviewer.jsonl", "prompt_path": "prompts/rakuda_prompt.jsonl"}, "ranking": [{"model_id": "rinna/japanese-gpt-neox-3.6b", "short_name": "rinna-3.6b", "median": -0.7503310531398228, "one_sigma_down": 0.10017338424683819, "one_sigma_up": 0.0991624823148497, "win_rate": 0.35125, "stronger_than_next_confidence": 0, "implied_win_probability": 0}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "short_name": "rinna-3.6b-SFT", "median": -0.7188850623809692, "one_sigma_down": 0.10084014078765635, "one_sigma_up": 0.09975039004731556, "win_rate": 0.35875, "stronger_than_next_confidence": 0.5853008474576271, "implied_win_probability": 0.5078608499333815}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "short_name": "rinna-3.6b-PPO", "median": -0.5753167201785611, "one_sigma_down": 0.09831405058106879, "one_sigma_up": 0.09829877789967173, "win_rate": 0.3925, "stronger_than_next_confidence": 0.8377531779661017, "implied_win_probability": 0.5358305621120212}, {"model_id": "izumi-lab/stormy-7b-10ep", "short_name": "stormy-7b", "median": -0.3835133333724112, "one_sigma_down": 0.09694851881151118, "one_sigma_up": 0.09754290728280562, "win_rate": 0.43875, "stronger_than_next_confidence": 0.9087330508474576, "implied_win_probability": 0.5478043820331442}, {"model_id": "cyberagent/open-calm-7b", "short_name": "open-calm-7b", "median": -0.06256778701634562, "one_sigma_down": 0.09747332104552651, "one_sigma_up": 0.09736005425987745, "win_rate": 0.515, "stronger_than_next_confidence": 0.9867192796610169, "implied_win_probability": 0.5795546717417311}, {"model_id": "gpt-3.5-turbo-0301:20230614", "short_name": "gpt-3.5", "median": 2.4877740910918504, "one_sigma_down": 0.17804337562614858, "one_sigma_up": 0.188354483423951, "win_rate": 0.94375, "stronger_than_next_confidence": 1.0, "implied_win_probability": 0.9275964789568163}]}
{"date": "2023-07-14T11:00:16.501707", "model_metadata": {"gpt-4:20230713": {"model_id": "gpt-4:20230713", "path": "answers/rakuda_v1/gpt4.jsonl"}, "gpt-3.5-turbo-0301:20230614": {"model_id": "gpt-3.5-turbo-0301:20230614", "path": "answers/rakuda_v1/gpt3.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-ppo": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "path": "answers/rakuda_v1/rinna-ppo.jsonl"}, "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2": {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "path": "answers/rakuda_v1/rinna-sft.jsonl"}, "rinna/japanese-gpt-neox-3.6b": {"model_id": "rinna/japanese-gpt-neox-3.6b", "path": "answers/rakuda_v1/rinna.jsonl"}, "izumi-lab/stormy-7b-10ep": {"model_id": "izumi-lab/stormy-7b-10ep", "path": "answers/rakuda_v1/stormy.jsonl"}, "cyberagent/open-calm-7b": {"model_id": "cyberagent/open-calm-7b", "path": "answers/rakuda_v1/calm.jsonl"}, "rwkv-world-jpn-55": {"model_id": "rwkv-world-jpn-55", "path": "answers/rakuda_v1/rwkv.jsonl"}, "super-torin-sama-alpha2": {"model_id": "super-torin-sama-alpha2", "path": "answers/rakuda_v1/super-torin.jsonl"}}, "metadata": {"questions_path": "questions/rakuda_v1.jsonl", "reviewer_path": "prompts/gpt4_reviewer.jsonl", "prompt_path": "prompts/rakuda_prompt.jsonl"}, "ranking": [{"model_id": "rinna/japanese-gpt-neox-3.6b", "median": 698.9913020475115, "one_sigma_up": 35.752530658702995, "one_sigma_down": 37.16706665602965, "stronger_than_next_confidence": -1.0, "win_rate": 0.1657754010695187, "short_name": "rinna-3.6b"}, {"model_id": "cyberagent/open-calm-7b", "median": 790.5125545608346, "one_sigma_up": 32.76924783587151, "one_sigma_down": 33.4477748571079, "stronger_than_next_confidence": 0.97221, "win_rate": 0.27325581395348836, "short_name": "open-calm-7b"}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2", "median": 810.8997957745601, "one_sigma_up": 33.78176273460815, "one_sigma_down": 33.44750949199499, "stronger_than_next_confidence": 0.670135, "win_rate": 0.29874213836477986, "short_name": "rinna-3.6b-SFT"}, {"model_id": "izumi-lab/stormy-7b-10ep", "median": 845.5325383470723, "one_sigma_up": 32.24765235411883, "one_sigma_down": 33.31176841593435, "stronger_than_next_confidence": 0.7628375, "win_rate": 0.3282208588957055, "short_name": "stormy-7b"}, {"model_id": "rinna/japanese-gpt-neox-3.6b-instruction-ppo", "median": 860.0227621752631, "one_sigma_up": 33.301513369329655, "one_sigma_down": 33.94073435505163, "stronger_than_next_confidence": 0.6201725, "win_rate": 0.38741721854304634, "short_name": "rinna-3.6b-PPO"}, {"model_id": "super-torin-sama-alpha2", "median": 1010.5062823376504, "one_sigma_up": 32.12812630650774, "one_sigma_down": 31.2491044571658, "stronger_than_next_confidence": 0.9997425, "win_rate": 0.5706214689265536, "short_name": "super-torin"}, {"model_id": "rwkv-world-jpn-55", "median": 1076.665210251055, "one_sigma_up": 34.25355778345056, "one_sigma_down": 33.80798216771973, "stronger_than_next_confidence": 0.9137775, "win_rate": 0.5338983050847458, "short_name": "rwkv-world"}, {"model_id": "gpt-3.5-turbo-0301:20230614", "median": 1384.010025877907, "one_sigma_up": 45.62727816672759, "one_sigma_down": 42.465529289006554, "stronger_than_next_confidence": 1.0, "win_rate": 0.8442211055276382, "short_name": "gpt-3.5"}, {"model_id": "gpt-4:20230713", "median": 1520.4348909092596, "one_sigma_up": 53.18798452138276, "one_sigma_down": 49.03475995474105, "stronger_than_next_confidence": 0.9935225, "win_rate": 0.9255813953488372, "short_name": "gpt-4"}]}
